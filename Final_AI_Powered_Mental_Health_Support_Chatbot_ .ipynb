{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "GaS-8hPrO9S6",
    "outputId": "08c9cee8-ce34-41cf-94a1-8e1768abcd3c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.0.0 fsspec-2025.3.0\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install transformers datasets pandas spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6P025TPTqr0"
   },
   "source": [
    "# **Part 1: Setting Up the Environment and Loading a Mental Health Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import datasets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "id": "eiARhtw9sW-3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653,
     "referenced_widgets": [
      "91b2543b85964eaebbc84a5dcf251162",
      "c6cf31df66df4c678b93551fdc8ef3c1",
      "7ab130e3ff13488e926f78e8c775eb05",
      "8640743d0f92424ba0ddf9324ef26971",
      "5e061ebd5b654ff8b3f08c0d7b7b1c5f",
      "5026e2c5c798447889eae20ad431ef0c",
      "85507726332d4bef9d6f7251b03278a6",
      "4fffb5e2ff1f4f268b5d17cfef32aeba",
      "77f63a2402564620b845dfa653e8b5bf",
      "7f688023890549e2adeb01537a55e9f3",
      "8bbb4474346844a79fe1bb49f517d820",
      "da15f386d7ab4d668b8dd31c18d1886d",
      "b04da5fc4a57437e9795c2d88cba051b",
      "578509b19f1b4c75916ff29c110c2400",
      "cde94cd815f04d5eb0aff20f8e6ce7fc",
      "106bf6df97984c8a8d3bfd75c63aa2b7",
      "50a2481cb4014b2f9f14c12962edf938",
      "032773a1fccd43deb9b4eb90941d7177",
      "9c91d5bcec594956b943efb18b2a15ff",
      "edc6df384cbc4ae4b3864840476c8bec",
      "df4d588513d64205bb8756297f7c5871",
      "246f47958be24d96b7fe9e628fa7978d",
      "074f7635ca924fc592a7fffce1cf8458",
      "4499cdcff62f43ce8f2041e5fa75a4bc",
      "c73b72eeceb242db933495ab5f66b641",
      "ef13c2725f9744858af010502385ea7e",
      "510d90bba7e841069268fa4e50c2a455",
      "03fa23b1107842098532ada8cbca689c",
      "048603dc7a934dd88586f22a287f95c6",
      "a0ad5f615f0c4994a6434c2b3cc92cac",
      "59fbed06c92845be84561061bea7fae8",
      "d77cb4e44a134ce79667bb1906a065be",
      "95800b773a16449d9dbedced49ae9f47"
     ]
    },
    "id": "uSFO6nWePFPP",
    "outputId": "b7ef0971-2ff4-4072-f155-5f82f772fe13"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91b2543b85964eaebbc84a5dcf251162"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "20220401_counsel_chat.csv: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da15f386d7ab4d668b8dd31c18d1886d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/2775 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "074f7635ca924fc592a7fffce1cf8458"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   questionID                              questionTitle  \\\n",
       "0           0  Do I have too many issues for counseling?   \n",
       "1           0  Do I have too many issues for counseling?   \n",
       "2           0  Do I have too many issues for counseling?   \n",
       "3           0  Do I have too many issues for counseling?   \n",
       "4           0  Do I have too many issues for counseling?   \n",
       "\n",
       "                                        questionText  \\\n",
       "0  I have so many issues to address. I have a his...   \n",
       "1  I have so many issues to address. I have a his...   \n",
       "2  I have so many issues to address. I have a his...   \n",
       "3  I have so many issues to address. I have a his...   \n",
       "4  I have so many issues to address. I have a his...   \n",
       "\n",
       "                                        questionLink       topic  \\\n",
       "0  https://counselchat.com/questions/do-i-have-to...  depression   \n",
       "1  https://counselchat.com/questions/do-i-have-to...  depression   \n",
       "2  https://counselchat.com/questions/do-i-have-to...  depression   \n",
       "3  https://counselchat.com/questions/do-i-have-to...  depression   \n",
       "4  https://counselchat.com/questions/do-i-have-to...  depression   \n",
       "\n",
       "                                       therapistInfo  \\\n",
       "0  Jennifer MolinariHypnotherapist & Licensed Cou...   \n",
       "1  Jason Lynch, MS, LMHC, LCAC, ADSIndividual & C...   \n",
       "2  Shakeeta TorresFaith Based Mental Health Couns...   \n",
       "3  Noorayne ChevalierMA, RP, CCC, CCAC, LLP (Mich...   \n",
       "4  Toni Teixeira, LCSWYour road to healing begins...   \n",
       "\n",
       "                                        therapistURL  \\\n",
       "0  https://counselchat.com/therapists/jennifer-mo...   \n",
       "1  https://counselchat.com/therapists/jason-lynch...   \n",
       "2  https://counselchat.com/therapists/shakeeta-to...   \n",
       "3  https://counselchat.com/therapists/noorayne-ch...   \n",
       "4  https://counselchat.com/therapists/toni-teixei...   \n",
       "\n",
       "                                          answerText  upvotes  views  \n",
       "0  It is very common for\u00a0people to have multiple ...        3   1971  \n",
       "1  I've never heard of someone having \"too many i...        2    386  \n",
       "2  Absolutely not.\u00a0 I strongly recommending worki...        2   3071  \n",
       "3  Let me start by saying there are never too man...        2   2643  \n",
       "4  I just want to acknowledge you for the courage...        1    256  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-7016cc68-56c5-4ee4-8db0-d1f5901d20af\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>questionTitle</th>\n",
       "      <th>questionText</th>\n",
       "      <th>questionLink</th>\n",
       "      <th>topic</th>\n",
       "      <th>therapistInfo</th>\n",
       "      <th>therapistURL</th>\n",
       "      <th>answerText</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Do I have too many issues for counseling?</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>https://counselchat.com/questions/do-i-have-to...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Jennifer MolinariHypnotherapist &amp; Licensed Cou...</td>\n",
       "      <td>https://counselchat.com/therapists/jennifer-mo...</td>\n",
       "      <td>It is very common for\u00a0people to have multiple ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Do I have too many issues for counseling?</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>https://counselchat.com/questions/do-i-have-to...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Jason Lynch, MS, LMHC, LCAC, ADSIndividual &amp; C...</td>\n",
       "      <td>https://counselchat.com/therapists/jason-lynch...</td>\n",
       "      <td>I've never heard of someone having \"too many i...</td>\n",
       "      <td>2</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Do I have too many issues for counseling?</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>https://counselchat.com/questions/do-i-have-to...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Shakeeta TorresFaith Based Mental Health Couns...</td>\n",
       "      <td>https://counselchat.com/therapists/shakeeta-to...</td>\n",
       "      <td>Absolutely not.\u00a0 I strongly recommending worki...</td>\n",
       "      <td>2</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Do I have too many issues for counseling?</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>https://counselchat.com/questions/do-i-have-to...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Noorayne ChevalierMA, RP, CCC, CCAC, LLP (Mich...</td>\n",
       "      <td>https://counselchat.com/therapists/noorayne-ch...</td>\n",
       "      <td>Let me start by saying there are never too man...</td>\n",
       "      <td>2</td>\n",
       "      <td>2643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Do I have too many issues for counseling?</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>https://counselchat.com/questions/do-i-have-to...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Toni Teixeira, LCSWYour road to healing begins...</td>\n",
       "      <td>https://counselchat.com/therapists/toni-teixei...</td>\n",
       "      <td>I just want to acknowledge you for the courage...</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7016cc68-56c5-4ee4-8db0-d1f5901d20af')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7016cc68-56c5-4ee4-8db0-d1f5901d20af button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7016cc68-56c5-4ee4-8db0-d1f5901d20af');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-da46e79a-ef0f-4b13-8faf-73b776848cab\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da46e79a-ef0f-4b13-8faf-73b776848cab')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-da46e79a-ef0f-4b13-8faf-73b776848cab button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df",
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2775,\n  \"fields\": [\n    {\n      \"column\": \"questionID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 307,\n        \"min\": 0,\n        \"max\": 939,\n        \"num_unique_values\": 940,\n        \"samples\": [\n          605,\n          63,\n          136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionTitle\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 933,\n        \"samples\": [\n          \"How can I know what my sexual orientation is?\",\n          \"My parents are getting a divorce and I feel depressed\",\n          \"My sister and my husband had an affair\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionText\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 865,\n        \"samples\": [\n          \"My partner lives in Canada while I live in the US. We visit each other, but we go months in between visits. I have anxiety, and I'm always anxious about him cheating or still having feelings for an ex that he dated for three years. He doesn't understand my anxiety. How do I stop myself from worrying so much?\",\n          \"I've been with him for a couple months. We will talk everyday and he will get mad over something I will say and not talk to me. We have our great moments, but I just need to focus on my personal situations, and I feel he is slowing me down with that. I still wanna be with him, but not now.\",\n          \"She treats me like I'm not in her presence. She\\u2019s always yelling at me for no reason. She gives more respect to my brothers than me, but only my brothers fight her while I respect her.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionLink\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 940,\n        \"samples\": [\n          \"https://counselchat.com/questions/why-can-t-i-stop-crying\",\n          \"https://counselchat.com/questions/i-have-long-spurts-of-depression-anxiety-and-need-change-constantly-why\",\n          \"https://counselchat.com/questions/i-hate-talking-to-people-much-less-strangers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"military-issues\",\n          \"marriage\",\n          \"stress\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"therapistInfo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 437,\n        \"samples\": [\n          \"Lisa Provorny\",\n          \"Adriana DyurichCOUNSELING, WELLNESS, AND CONSULTING for for Moms, moms to be and their children\",\n          \"Amy Fortney ParksChild & Adolescent Psychologist, Parent Coach, Educational Consultant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"therapistURL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 433,\n        \"samples\": [\n          \"https://counselchat.com/therapists/ida-duplechin\",\n          \"https://counselchat.com/therapists/amelia-mora-mars\",\n          \"https://counselchat.com/therapists/rebecca-wong\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answerText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2738,\n        \"samples\": [\n          \"It sounds like you have been thinking about how past hurts have influenced you, and when you try to talk about these hurts with people in your life, you are feeling invalidated. It also sounds like current conflicts are continuing to leave you feeling hurt and devalued. In working with a therapist, you may be able to get some clarity about your past, who you are, and what kinds of boundaries you want in your relationships, so that you can lead a life that is more satisfying to you.\",\n          \"I've heard people say that they cut themselves as a way to feel relief from different emotions. You're also right that when you try to focus on just not cutting, it becomes more difficult because it's what you are focused on. While that is still something to work on, it may also be helpful to find something else you can do instead. You said drawing doesn't work for you. Sometimes more physical activities, such as doing a few jumping jacks, can be helpful. If you don't exercise, it might be something to talk with your doctor about first.The more you can learn about what makes you want to cut, the easier it will be to find out what you could do to change that. Try talking to somebody about what you are feeling in addition to the urge to cut.\",\n          \"You already are doing that! You are reaching out (virtually still counts!). You are accepting your past, you are not denying what happened to you, you are talking about the past. You are already doing a great job of starting this journey. You get your life back by doing things differently.I would think about how you would like to process your past. Do you want to talk to someone? Do you want to write about it? Do you want to pray about it? Do you want to read and research books about trauma? Take some time and think about what you want to do. Think about what would work for you and dive in. I am a Licensed Professional Counselor, so I am biased - but I really believe that counseling works. Having an objective, professional voice that can guide you on this process is so valuable. But please choose what makes you feel comfortable - not what everyone else says. I think you are very brave for reaching out and wanting to work on this. That takes a tremendous amount of courage and strength.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4,\n          3,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 796,\n        \"min\": 1,\n        \"max\": 16738,\n        \"num_unique_values\": 732,\n        \"samples\": [\n          387,\n          187,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"nbertagnolli/counsel-chat\")\n",
    "df = pd.DataFrame(ds['train'])  # Convert train split to Pandas DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZO_AJv9RDdE",
    "outputId": "4432a08e-f993-4529-d317-bb8e6a3be00e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset Shape: (2775, 10)\n",
      "\n",
      "First 5 Rows:\n",
      "   questionID                              questionTitle  \\\n",
      "0           0  Do I have too many issues for counseling?   \n",
      "1           0  Do I have too many issues for counseling?   \n",
      "2           0  Do I have too many issues for counseling?   \n",
      "3           0  Do I have too many issues for counseling?   \n",
      "4           0  Do I have too many issues for counseling?   \n",
      "\n",
      "                                        questionText  \\\n",
      "0  I have so many issues to address. I have a his...   \n",
      "1  I have so many issues to address. I have a his...   \n",
      "2  I have so many issues to address. I have a his...   \n",
      "3  I have so many issues to address. I have a his...   \n",
      "4  I have so many issues to address. I have a his...   \n",
      "\n",
      "                                        questionLink       topic  \\\n",
      "0  https://counselchat.com/questions/do-i-have-to...  depression   \n",
      "1  https://counselchat.com/questions/do-i-have-to...  depression   \n",
      "2  https://counselchat.com/questions/do-i-have-to...  depression   \n",
      "3  https://counselchat.com/questions/do-i-have-to...  depression   \n",
      "4  https://counselchat.com/questions/do-i-have-to...  depression   \n",
      "\n",
      "                                       therapistInfo  \\\n",
      "0  Jennifer MolinariHypnotherapist & Licensed Cou...   \n",
      "1  Jason Lynch, MS, LMHC, LCAC, ADSIndividual & C...   \n",
      "2  Shakeeta TorresFaith Based Mental Health Couns...   \n",
      "3  Noorayne ChevalierMA, RP, CCC, CCAC, LLP (Mich...   \n",
      "4  Toni Teixeira, LCSWYour road to healing begins...   \n",
      "\n",
      "                                        therapistURL  \\\n",
      "0  https://counselchat.com/therapists/jennifer-mo...   \n",
      "1  https://counselchat.com/therapists/jason-lynch...   \n",
      "2  https://counselchat.com/therapists/shakeeta-to...   \n",
      "3  https://counselchat.com/therapists/noorayne-ch...   \n",
      "4  https://counselchat.com/therapists/toni-teixei...   \n",
      "\n",
      "                                          answerText  upvotes  views  \n",
      "0  It is very common for\u00a0people to have multiple ...        3   1971  \n",
      "1  I've never heard of someone having \"too many i...        2    386  \n",
      "2  Absolutely not.\u00a0 I strongly recommending worki...        2   3071  \n",
      "3  Let me start by saying there are never too man...        2   2643  \n",
      "4  I just want to acknowledge you for the courage...        1    256  \n",
      "\n",
      "Columns: ['questionID', 'questionTitle', 'questionText', 'questionLink', 'topic', 'therapistInfo', 'therapistURL', 'answerText', 'upvotes', 'views']\n"
     ]
    }
   ],
   "source": [
    "# Basic exploration\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh5nuDfXR7u4"
   },
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to questionText and answerText columns\n",
    "df['question_clean'] = df['questionText'].apply(preprocess_text)\n",
    "df['answer_clean'] = df['answerText'].apply(preprocess_text)\n",
    "\n",
    "# Remove rows with missing or empty text\n",
    "df = df.dropna(subset=['questionText', 'answerText'])\n",
    "df = df[df['question_clean'] != \"\"]\n",
    "df = df[df['answer_clean'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEk6EDpeTY3L",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d56b25f2-de0e-405d-9db4-78e97d3dcd73"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Preprocessed Data Saved. Shape: (2609, 12)\n",
      "\n",
      "Sample Preprocessed Data:\n",
      "                                      question_clean  \\\n",
      "0  issues address history sexual abuse breast can...   \n",
      "1  issues address history sexual abuse breast can...   \n",
      "2  issues address history sexual abuse breast can...   \n",
      "3  issues address history sexual abuse breast can...   \n",
      "4  issues address history sexual abuse breast can...   \n",
      "\n",
      "                                        answer_clean  \n",
      "0  common people multiple issues want need addres...  \n",
      "1  heard having issues therapy effective competen...  \n",
      "2  absolutely strongly recommending working issue...  \n",
      "3  let start saying concerns bring counselling fa...  \n",
      "4  want acknowledge courage step support overwhel...  \n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "df.to_csv('/content/counselchat_preprocessed.csv', index=False)\n",
    "print(\"\\nPreprocessed Data Saved. Shape:\", df.shape)\n",
    "print(\"\\nSample Preprocessed Data:\")\n",
    "print(df[['question_clean', 'answer_clean']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-o6S42vTrvR"
   },
   "source": [
    "# **Part 2: Implementing Sentiment Analysis for Emotion Detection**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0QHBR6eTulA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNUJBiUJUNFF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3a08efc0-28d9-4ca7-e509-88b0b7346589"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Load preprocessed data from Part 1\n",
    "try:\n",
    "    df = pd.read_csv('/content/counselchat_preprocessed.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'counselchat_preprocessed.csv' not found.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvfEJm5zUSc1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245,
     "referenced_widgets": [
      "9d3ca64c7c7743fc8a75109cb61952ae",
      "cda5f0121fcd4f17bb8867d4cf85bbe0",
      "4a2fbe2435d44378afe2b6ababb3ffd9",
      "6ffed74773ab417ab879eea5b3ebee4a",
      "0bd30af5534b43d6a6551406664a3522",
      "eec01ffd433e4c168e0b64300ebc7b24",
      "42f07b27feda4bb8918cdb6cb6a399bc",
      "1c4b5b1742b84bcfb3b42cbbbf3d73f7",
      "fdc5a24cc9c24a7cb512707cc0aac2a2",
      "a84f6c32d2e640e484b35818ce1fae36",
      "56c76f0ad848487fab66c90cabd9b595",
      "cf0da70f91374a6dacd08ab6303aacb0",
      "1513453ad1fb4f7b9d5869798152968b",
      "cf14cbcbd66c43ab97e30f0dcd5a95b7",
      "de08945e295f46dd9e821137e784ebc7",
      "c79f0e0b2d824cfd9ce9043cf4080900",
      "4bcd92950bf04d47a80231f1c0871b8e",
      "b803398111b64fc8887e07ce0a5c7569",
      "15024657a30840038c529ecf0d6e325f",
      "5000271898df4aa3bc791737207fe56a",
      "063ebb63256b4990aaac744b639de695",
      "fc128bd7980944d589b1857a30c28c77",
      "0890a1eefb8f49b4aff229f38c0a51a3",
      "34855d0437cb43218fda134c1c4480f1",
      "bfdf3e78498c4fcb9f90208a93a72180",
      "e000dc6b525542dcbb0d2039c438d531",
      "cfbd5cc7b3e44b3d84cc2207e2487621",
      "c1f59edcf91e4f979b84f52230e1e317",
      "df0b1c4586bc45a4a8220699e425903f",
      "c6668bdff37d488eba1e41b775fb6677",
      "88e7d9ada5cd41439cdaedf2d212e1f9",
      "e88a45284cb44cd1aa1216d5cf15f713",
      "b5c6d6016110492d84c951a09069adab",
      "32b4e054d17f4f35919d78472afa1829",
      "51472a86851b4c1481150457e1d13a53",
      "bdc6ae510a774865a014203c61e5eb3e",
      "1a963950adb04f1aae9a535ddb60aee7",
      "fab9263c50d54dbdaad805121b5f1457",
      "eafc857a5d534c9ab195ff4e546d9fc1",
      "75615cc8efce44228753ca545174d6d1",
      "1f05030c78884700b378c32245fd3acc",
      "208a352c877a4d5cb0d2401cffecf54e",
      "535989aa783c46b9912ba3bde1f8cada",
      "0410fa2756214a8f86bf3aaf5df91bf5",
      "759dea82c50847cab385e317e717b976",
      "a9fbc7967ad84b11a654698f2d081965",
      "d6a155cb59a64783a450f497a8e80150",
      "9e1e5499fafa43de9cbf7a4f155a80a7",
      "2574772c4ba64965965b27c9c8cbea03",
      "93e97587e31d4db0bcb265cbcb9d9882",
      "d8b07feb540b47ccba9b84d399b226fc",
      "c43d81b9cf614ea9872b0fc67d2d18e6",
      "f346932a26de470b9c23c6c973781a75",
      "173080ab556e4cac8e6f65f8f9b179d4",
      "fc4962bcd5ad4951bb2a8432a8a68d0e",
      "814bce6640964098a42c63e877042c84",
      "dff2e73ab1cf46afba6795e9375d6ae4",
      "b5c568b487ac4117ad41835c7974b220",
      "13ff69e18dd54a5c8a60273ab636d984",
      "364943546c4d495abccff0d5e8cf73fe",
      "8e509fb189a54f0e998919e447445af4",
      "90abe0ee67cc44ebacf9748e0978abbe",
      "3ef407e41ff94a1ba9bafbc0ccdae32c",
      "90124667531d4c2aaaa40b8b1bd7eae9",
      "2ccbac98c69b47c9a42b7dea2cbdb83b",
      "6404fd27b0f342c5b92bfd4c5acb8322"
     ]
    },
    "outputId": "76a35c58-d465-4799-aefc-63cd4b014fb0"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d3ca64c7c7743fc8a75109cb61952ae"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf0da70f91374a6dacd08ab6303aacb0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0890a1eefb8f49b4aff229f38c0a51a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32b4e054d17f4f35919d78472afa1829"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "759dea82c50847cab385e317e717b976"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "814bce6640964098a42c63e877042c84"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Pseudo-label with twitter-roberta for better sentiment labels\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\", device=0 if torch.cuda.is_available() else -1)\n",
    "def get_sentiment(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return \"NEUTRAL\"\n",
    "    result = classifier(text)[0]\n",
    "    label = result['label']  # LABEL_0 (NEGATIVE), LABEL_1 (NEUTRAL), LABEL_2 (POSITIVE)\n",
    "    return {\"LABEL_0\": \"NEGATIVE\", \"LABEL_1\": \"NEUTRAL\", \"LABEL_2\": \"POSITIVE\"}[label]\n",
    "\n",
    "# Sample 600 samples to allow balancing\n",
    "df_subset = df[['question_clean']].dropna().sample(600, random_state=42)\n",
    "df_subset['sentiment'] = df_subset['question_clean'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c91Tuo4Ug9P",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9910f3f3-d9fe-4a2d-9ebf-39834637686d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial Label Distribution:\n",
      "sentiment\n",
      "NEGATIVE    311\n",
      "NEUTRAL     255\n",
      "POSITIVE     34\n",
      "Name: count, dtype: int64\n",
      "Balanced Label Distribution:\n",
      "sentiment\n",
      "NEGATIVE    200\n",
      "NEUTRAL     200\n",
      "POSITIVE    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Balance the dataset\n",
    "print(\"Initial Label Distribution:\")\n",
    "print(df_subset['sentiment'].value_counts())\n",
    "\n",
    "# Oversample minority classes\n",
    "neutral_samples = df_subset[df_subset['sentiment'] == \"NEUTRAL\"].sample(200, replace=True, random_state=42)\n",
    "positive_samples = df_subset[df_subset['sentiment'] == \"POSITIVE\"].sample(200, replace=True, random_state=42)\n",
    "negative_samples = df_subset[df_subset['sentiment'] == \"NEGATIVE\"].sample(200, random_state=42)\n",
    "df_balanced = pd.concat([negative_samples, neutral_samples, positive_samples])\n",
    "\n",
    "print(\"Balanced Label Distribution:\")\n",
    "print(df_balanced['sentiment'].value_counts())\n",
    "\n",
    "# Map sentiments to numeric labels\n",
    "sentiment_map = {\"POSITIVE\": 2, \"NEUTRAL\": 1, \"NEGATIVE\": 0}\n",
    "df_balanced['label'] = df_balanced['sentiment'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wht20reWVI-f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "471159fc509a418a96bfce0ee8a19cfe",
      "202b3c33a03a4a8ead21971647b158ad",
      "d3a895bce94e4c2481b41b6d73f3b33d",
      "b6b42cd6c82b429384bd74ea2fb33a21",
      "f4624dbcec684d97bbfb82a2d93c1b40",
      "e2439c494b7b49d08457396f8c021120",
      "a548093ab4a449e79c3f20daa187545d",
      "cc6577fb8f234ad4845ecd0360e5cd09",
      "8bb7d0c4f75241319707e71569878b7e",
      "ed3e153d15194acf81219c20f2660748",
      "9561e8fd3337400abf728bbd433c5c52",
      "260e26c9201a4987a79e7c291a8f79c1",
      "0924b331be1b4bffa48b14af88c61d32",
      "0eeccf18450b4a189850c9d151703003",
      "630bd8037fae41c5a908cadf62c053ab",
      "ad814e96acae48f9a55b970623d85149",
      "8dd5caa62db54c4eb708752c65519d15",
      "81788070bd86424b8cca0e4741e0f2a3",
      "29f865cccbd44269a9d3e4c04d619914",
      "070fd651db3c43dca0d1694279214ee1",
      "17294d546607433b8889af6c6c5a6df0",
      "af0697059a3f4283834a28b02d767773",
      "8312c6992a6a43db8e65eef3d2b457a8",
      "2a359c574fa141b1a07894e7f25d2b82",
      "33ec56e2fc07495eb29d25d32ed84130",
      "4333bdb2dadd44fc807170f674432435",
      "230c3604525c47d6910ee06473a820f9",
      "589f16c183c64e99b7bb873b6711e72f",
      "089f0a9db31c4046af86f2a44d433943",
      "5c80dfe8c9734c63802ee9da0d152a07",
      "f6fcf233a10f4f1488ba7bb864d60023",
      "72b70c4e314643bdaba0273c633c1644",
      "3065f0bd3c4b49f0ad8f12e6d7e200f4",
      "6be2fd0be31d47e7b0ec450ace75f59a",
      "0da9730995894a34b90c1f218696552f",
      "1dd275ed8f234f6cb40021c1af341c56",
      "02dfb0129d2649458679b7611f99487c",
      "d583633fe7e54392856c463cb2942e4a",
      "9ae6834da82c45b0b37c0e9f7e898d4b",
      "d7869451ce88411e9209c962ce1bd2b5",
      "f601f2e03de24a0d8ed7f8f44a19d265",
      "19e85bd25eba480cac6769c7944a7659",
      "4cf9c7ff72cf47229769ceb2bdafc0c1",
      "6136ace14c9c44db93285022c6180905"
     ]
    },
    "outputId": "2f2de5ce-ebb7-4747-f6b3-285e5d0367eb"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "471159fc509a418a96bfce0ee8a19cfe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "260e26c9201a4987a79e7c291a8f79c1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8312c6992a6a43db8e65eef3d2b457a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6be2fd0be31d47e7b0ec450ace75f59a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Step 3: Prepare data for fine-tuning\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "df_balanced['input_ids'] = df_balanced['question_clean'].apply(lambda x: tokenize_function(x)['input_ids'])\n",
    "df_balanced['attention_mask'] = df_balanced['question_clean'].apply(lambda x: tokenize_function(x)['attention_mask'])\n",
    "\n",
    "# Convert to torch dataset\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(df_balanced, test_size=0.2, random_state=42)\n",
    "train_dataset = SentimentDataset(\n",
    "    {'input_ids': train_df['input_ids'].tolist(), 'attention_mask': train_df['attention_mask'].tolist()},\n",
    "    train_df['label'].tolist()\n",
    ")\n",
    "test_dataset = SentimentDataset(\n",
    "    {'input_ids': test_df['input_ids'].tolist(), 'attention_mask': test_df['attention_mask'].tolist()},\n",
    "    test_df['label'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8niQ15JyVOA3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560,
     "referenced_widgets": [
      "84c34cd62a2b4af18a7ef03afda07901",
      "3e8888da7ce744248c533153970cf5b3",
      "0d9fa9ace6174606b08e7bbe63b57e30",
      "d25e72aad6c44ff6b557b1659c581c62",
      "f949d41459434d83ba9d14f8356824da",
      "63b7643079de4fc79fd6b1dd4a8b1b6f",
      "37d5cf184e694736bbbe02d6bfea16da",
      "41bc8d8853b24a04b68466d77314eb93",
      "966cb3a86acb4391b0a1936412ec9667",
      "3797828c5b3645298909fe462e679847",
      "310954ff01894afda7bcb91babcb01c3"
     ]
    },
    "outputId": "c11bbff7-9faa-4d71-e104-02207657e145"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84c34cd62a2b4af18a7ef03afda07901"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpavova8202\u001b[0m (\u001b[33mpavova8202-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250714_113242-xrotprip</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pavova8202-/huggingface/runs/xrotprip' target=\"_blank\">/content/sentiment_model_improved</a></strong> to <a href='https://wandb.ai/pavova8202-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/pavova8202-/huggingface' target=\"_blank\">https://wandb.ai/pavova8202-/huggingface</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/pavova8202-/huggingface/runs/xrotprip' target=\"_blank\">https://wandb.ai/pavova8202-/huggingface/runs/xrotprip</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.957398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.142896</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.957398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.108164</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation Results: {'eval_loss': 0.10816408693790436, 'eval_accuracy': 0.9666666666666667, 'eval_f1': 0.9660740811476105, 'eval_runtime': 0.5239, 'eval_samples_per_second': 229.052, 'eval_steps_per_second': 28.632, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fine-tune DistilBERT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(device)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/sentiment_model_improved\",\n",
    "    num_train_epochs=10,  # Increased epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"/content/logs_sentiment\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",  # Updated to eval_strategy\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda pred: {\n",
    "        \"accuracy\": accuracy_score(pred.label_ids, pred.predictions.argmax(-1)),\n",
    "        \"f1\": f1_score(pred.label_ids, pred.predictions.argmax(-1), average='weighted')\n",
    "    }\n",
    ")\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pr6hBfxhVRFL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c13e6a55-a712-46a4-e5c6-35c5e03d61ac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fine-tuned model saved to /content/sentiment_model_improved\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save the fine-tuned model\n",
    "model.save_pretrained(\"/content/sentiment_model_improved\")\n",
    "tokenizer.save_pretrained(\"/content/sentiment_model_improved\")\n",
    "print(\"Fine-tuned model saved to /content/sentiment_model_improved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8Pw4xNwVSdw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5031c964-5a3e-44b8-f149-472c55873bb9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: I\u2019m really struggling with anxiety\n",
      "Predicted Sentiment: NEGATIVE\n",
      "\n",
      "Input: I just got promoted and I\u2019m thrilled\n",
      "Predicted Sentiment: POSITIVE\n",
      "\n",
      "Input: What are some ways to cope with sadness?\n",
      "Predicted Sentiment: NEUTRAL\n",
      "\n",
      "Input: Life feels meaningless sometimes\n",
      "Predicted Sentiment: NEGATIVE\n",
      "\n",
      "Input: I\u2019m okay, just navigating some challenges\n",
      "Predicted Sentiment: NEUTRAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Test sentiment prediction\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Move all inputs to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2: \"POSITIVE\"}[pred]\n",
    "\n",
    "test_texts = [\n",
    "    \"I\u2019m really struggling with anxiety\",\n",
    "    \"I just got promoted and I\u2019m thrilled\",\n",
    "    \"What are some ways to cope with sadness?\",\n",
    "    \"Life feels meaningless sometimes\",\n",
    "    \"I\u2019m okay, just navigating some challenges\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    sentiment = predict_sentiment(text)\n",
    "    print(f\"Input: {text}\\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuUSFwfmq6Na"
   },
   "source": [
    "\n",
    "# **Part 3: Crisis Detection**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set device for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Load preprocessed data from Part 1\n",
    "try:\n",
    "    df = pd.read_csv('/content/counselchat_preprocessed.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'counselchat_preprocessed.csv' not found.\")\n",
    "    exit()\n"
   ],
   "metadata": {
    "id": "OY7zkvGnrz50",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2d6404e3-fbc6-4b4c-ded9-1385d91479db"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0FzUc4Gq6yV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "af00da11-a2b0-45cd-d286-b43606975d46"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Crisis Label Distribution:\n",
      "crisis_label\n",
      "0    250\n",
      "1    250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create crisis dataset\n",
    "crisis_keywords = [\"suicide\", \"kill myself\", \"don\u2019t want to live\", \"hopeless\", \"end my life\", \"worthless\", \"giving up\"]\n",
    "def label_crisis(text):\n",
    "    return 1 if any(keyword in text.lower() for keyword in crisis_keywords) else 0\n",
    "\n",
    "crisis_data = df[['question_clean']].dropna().sample(500, random_state=42)\n",
    "crisis_data['crisis_label'] = crisis_data['question_clean'].apply(label_crisis)\n",
    "\n",
    "# Balance dataset (250 crisis, 250 non-crisis)\n",
    "crisis_data = pd.concat([\n",
    "    crisis_data[crisis_data['crisis_label'] == 0].sample(250, random_state=42),\n",
    "    crisis_data[crisis_data['crisis_label'] == 1].sample(250, replace=True, random_state=42)\n",
    "])\n",
    "print(\"Crisis Label Distribution:\")\n",
    "print(crisis_data['crisis_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ks4u6uMNrITr"
   },
   "outputs": [],
   "source": [
    "# Step 2: Tokenize data\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "crisis_data['input_ids'] = crisis_data['question_clean'].apply(lambda x: tokenize_function(x)['input_ids'])\n",
    "crisis_data['attention_mask'] = crisis_data['question_clean'].apply(lambda x: tokenize_function(x)['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BczOIJTfrK-Q"
   },
   "outputs": [],
   "source": [
    "# Step 3: Create torch dataset\n",
    "class CrisisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(crisis_data, test_size=0.2, random_state=42)\n",
    "train_dataset = CrisisDataset(\n",
    "    {'input_ids': train_df['input_ids'].tolist(), 'attention_mask': train_df['attention_mask'].tolist()},\n",
    "    train_df['crisis_label'].tolist()\n",
    ")\n",
    "test_dataset = CrisisDataset(\n",
    "    {'input_ids': test_df['input_ids'].tolist(), 'attention_mask': test_df['attention_mask'].tolist()},\n",
    "    test_df['crisis_label'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0N5rk3idrNgx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "outputId": "0b43af07-0077-4555-94bc-e5702e453725"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Crisis Classifier Evaluation Results: {'eval_loss': 0.0005876069772057235, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 0.4063, 'eval_samples_per_second': 246.135, 'eval_steps_per_second': 31.998, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fine-tune DistilBERT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2).to(device)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/crisis_model\",\n",
    "    num_train_epochs=10,  # Increased epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,  # Added for stable training\n",
    "    warmup_steps=100,  # Added for gradual learning rate increase\n",
    "    weight_decay=0.01,  # Added to prevent overfitting\n",
    "    logging_dir=\"/content/logs_crisis\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",  # Updated to eval_strategy\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda pred: {\n",
    "        \"accuracy\": accuracy_score(pred.label_ids, pred.predictions.argmax(-1)),\n",
    "        \"f1\": f1_score(pred.label_ids, pred.predictions.argmax(-1), average='weighted')\n",
    "    }\n",
    ")\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Crisis Classifier Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJHHtRVfrTSg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d6ee2a84-a39f-44de-98b6-8490854bd80e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fine-tuned crisis model saved to /content/crisis_model\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save the model\n",
    "model.save_pretrained(\"/content/crisis_model\")\n",
    "tokenizer.save_pretrained(\"/content/crisis_model\")\n",
    "print(\"Fine-tuned crisis model saved to /content/crisis_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqSCpB3zrT5X",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a68a2d03-4611-4baa-a92d-9621aa6bd837"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: I feel worthless and don\u2019t want to live\n",
      "Predicted: NON-CRISIS\n",
      "\n",
      "Input: I\u2019m okay, just feeling a bit down\n",
      "Predicted: NON-CRISIS\n",
      "\n",
      "Input: I\u2019m thinking about suicide\n",
      "Predicted: NON-CRISIS\n",
      "\n",
      "Input: What are some ways to manage stress?\n",
      "Predicted: NON-CRISIS\n",
      "\n",
      "Input: Life feels hopeless sometimes\n",
      "Predicted: NON-CRISIS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Test the model\n",
    "def predict_crisis(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return \"CRISIS\" if pred == 1 else \"NON-CRISIS\"\n",
    "\n",
    "test_texts = [\n",
    "    \"I feel worthless and don\u2019t want to live\",\n",
    "    \"I\u2019m okay, just feeling a bit down\",\n",
    "    \"I\u2019m thinking about suicide\",\n",
    "    \"What are some ways to manage stress?\",\n",
    "    \"Life feels hopeless sometimes\"\n",
    "]\n",
    "for text in test_texts:\n",
    "    crisis_pred = predict_crisis(text)\n",
    "    print(f\"Input: {text}\\nPredicted: {crisis_pred}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaAZzSzLJ_TA"
   },
   "source": [
    "# **Part 4: Response Generation**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Load preprocessed data from Part 1\n",
    "try:\n",
    "    df = pd.read_csv('/content/counselchat_preprocessed.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'counselchat_preprocessed.csv' not found. Run Part 1 first.\")\n",
    "    exit()"
   ],
   "metadata": {
    "id": "nHCJnfAAoFqS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1bf0fb1c-28ae-4a85-e5f4-2d839015ad3a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 1: Prepare dialogue data\n",
    "dialogpt_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")  # Use medium model for better performance\n",
    "dialogpt_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\").to(device)\n",
    "dialogpt_tokenizer.pad_token = dialogpt_tokenizer.eos_token\n",
    "\n",
    "# Use raw answerText and questionText to preserve natural language\n",
    "dialogue_data = df[['questionText', 'answerText']].dropna().sample(1000, random_state=42)  # Increase sample size for better training\n",
    "\n",
    "def prepare_dialogue_data(row):\n",
    "    input_text = row['questionText']\n",
    "    target_text = row['answerText'][:500]  # Limit length for stability\n",
    "    # Combine input and target for conversational context\n",
    "    input_encodings = dialogpt_tokenizer(\n",
    "        input_text + dialogpt_tokenizer.eos_token + target_text,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': input_encodings['input_ids'].squeeze(),\n",
    "        'attention_mask': input_encodings['attention_mask'].squeeze(),\n",
    "        'labels': input_encodings['input_ids'].squeeze()  # Use input_ids as labels for causal LM\n",
    "    }\n",
    "\n",
    "dialogue_dataset = [prepare_dialogue_data(row) for _, row in dialogue_data.iterrows()]\n",
    "train_data, eval_data = train_test_split(dialogue_dataset, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "dqcVuf7moJ3P",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "b24146d7004e4ad891c3e75da7d19348",
      "feed7a53d4b240e186a66a15dde64d1a",
      "4ba85900de60491a909f2a3dc843c135",
      "f898cbd5d756449299c60b41bb653e6a",
      "f4604aa5c0ef4c20880520ebcd88dec5",
      "66f4b8c5fd80464b91af0b43b2d4db85",
      "1cd1b65a44014ef0bde33bc8185e998b",
      "b12185697d2c4d36a432143b6e5ffd17",
      "0be30682e82e417a81bab2ac703fd44a",
      "bfb441e5072e4eb78ca45d3d1b4c3d58",
      "3864d11dc2cd47c5a2643151e6710a03",
      "92d5d5e2b91d425da9a23b6bd6dae932",
      "29d3d98cfea24d7386b67acfa000363e",
      "1dc9736c6eda4d939c50f08d5857902c",
      "2dae3dd9b834439fbff8fc1be91aa5ce",
      "7c1d090776be440cac863fb23e8496bf",
      "db356d5296e1421abb3cc216d88a9869",
      "12ec213ba417404a9348e2e88d495545",
      "6dcbe736d1894424b3155854c6a6548e",
      "9e73b81d0b184234b4415a19892e3d84",
      "a2f77bf20e7d4ebebac30f0a6ce0afca",
      "861a82b196384e3b8bcc232d290feb74",
      "373b944023b04d728e237b69781347ad",
      "da8baf8dfbe94d92b9844963808e10d7",
      "082f54a96533469ab4aa7ebddcf5b5ae",
      "8ea977e0ebc340f38db2e064fbb96cef",
      "4df70ef90fa04161a88e0c710e20b3b7",
      "dfcce7e0e05b4e618c55197be8168bf2",
      "9e91dec2992f4e89803494e469c4ecbd",
      "69203d0e6d1f4b3ca177a00d9e6b0cd8",
      "376d990a870c46a788d809a9d436b046",
      "c7fc1648985049859ca8c5dfd944af43",
      "194bac9649444f779ee419e786d03d6e",
      "15965da509e64f4eabbe0b5455c62343",
      "26fe584ab40547f9ad81eddb93dba06c",
      "49f36c980a42401ea13c2ed72969eb93",
      "11cbc6709daa4702a2757d7af1bb6af4",
      "2eb21c6e46fa470caa93361d825306c2",
      "0d0a319076a144a0af13b77371cd6565",
      "26f8f325eac4481581420444a246082a",
      "29b45f5d67394c08b491476f5fc54fa1",
      "d9a592d773194486920dbb025198a327",
      "3bc3865de34944e7a7a09fc8733ce9e2",
      "a6e24884e05e49ea9b758559f2c3f192",
      "b8463fc6d2dd4466b84f472651ad9a6e",
      "341a3f47f82c4015860fdb05d16940c7",
      "588548a9643c49849bcc5a8133589339",
      "b078de794d6d4cd59006c29ff3725e5b",
      "d6c148afb297434686db67a7ea6c3b22",
      "f854632b539a473692cd33bcbf033cc7",
      "a30f6d11da7e4e4fad7c9b5081266d61",
      "372c590fe87b410a8a370206152141d6",
      "9efa231549464adeac0bebfec1c83143",
      "4276b7dc85104b3185b0dfd07723e5a9",
      "315817a4de41499893a7e97b727c33c3",
      "b72cb1db8e8f4947b8771135a9f34379",
      "8273695014a04ce2bf85875f7b050c3b",
      "d371eb030ec142b4854ffb05f3d3310c",
      "1199aef55aeb495281a1f6a8155e162a",
      "7b0fdd56d02b4389a9225683ef1e98bd",
      "53629a9e06a7425c8c7cfc69e1566e03",
      "f9c4e50d9c6c45089e0331e479e95184",
      "ffb2f71fe6e84f9c8b92be5ce600748d",
      "6207f7b68d974d14b4b6b25dd8d12134",
      "4425f44c016349bb96e04e6a5e5e5939",
      "d6625cc3bf52461e965155a0d4140bd1",
      "415dfac447fb4fea8c83ca54dfaa74c5",
      "6e155739cf034ee7a06185f2debaa45d",
      "85b4f87dcf2348a1bd31e43d5bb731aa",
      "4464d6cd4cca49d1abaab369207253a1",
      "84f6b7298b1c4e99b31e35d59700ffd7",
      "96e4ab6fda9b4bac83ef6c7ed90cb6f2",
      "4c9941f3fc7c4e89be406081a2af1ca6",
      "12ce222e50d341be8a02570a113bd849",
      "f406c51e92334e9aa9a8fa69190aea02",
      "fd6b71c88e7649b4b5d678ac37d328b7",
      "14175e96dcf244d7b70ebd8b7b19fdaf"
     ]
    },
    "outputId": "9f45f862-0560-48ee-d340-8e9b4ed5ef7f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b24146d7004e4ad891c3e75da7d19348"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92d5d5e2b91d425da9a23b6bd6dae932"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "373b944023b04d728e237b69781347ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15965da509e64f4eabbe0b5455c62343"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8463fc6d2dd4466b84f472651ad9a6e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b72cb1db8e8f4947b8771135a9f34379"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "415dfac447fb4fea8c83ca54dfaa74c5"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Create torch dataset\n",
    "class DialogueDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.data[idx]['input_ids'],\n",
    "            'attention_mask': self.data[idx]['attention_mask'],\n",
    "            'labels': self.data[idx]['labels']\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "train_dataset = DialogueDataset(train_data)\n",
    "eval_dataset = DialogueDataset(eval_data)"
   ],
   "metadata": {
    "id": "CvpUih4ToSgp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3: Fine-tune DialoGPT with improved parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/dialogpt_finetuned\",\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"/content/logs_dialogpt\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=dialogpt_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"DialoGPT Evaluation Results:\", eval_results)"
   ],
   "metadata": {
    "id": "N8DadBwioW2Q",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "outputId": "803ef35c-d3a9-4dd3-b4b0-013b957cd844"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 13:37, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.865700</td>\n",
       "      <td>2.850259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.498900</td>\n",
       "      <td>2.703285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.336200</td>\n",
       "      <td>2.682057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:05]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DialoGPT Evaluation Results: {'eval_loss': 2.6820573806762695, 'eval_runtime': 5.7274, 'eval_samples_per_second': 34.92, 'eval_steps_per_second': 4.365, 'epoch': 6.0}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4: Save the model\n",
    "dialogpt_model.save_pretrained(\"/content/dialogpt_finetuned\")\n",
    "dialogpt_tokenizer.save_pretrained(\"/content/dialogpt_finetuned\")\n",
    "print(\"Fine-tuned DialoGPT saved to /content/dialogpt_finetuned\")"
   ],
   "metadata": {
    "id": "BwP9TvfSoZYf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "605bec3d-918c-4827-a9ab-d08d28d8046b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fine-tuned DialoGPT saved to /content/dialogpt_finetuned\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5: Test the model\n",
    "def generate_response(text):\n",
    "    prompt = (\n",
    "        \"You are a compassionate mental health assistant. \"\n",
    "        \"Respond in a supportive and helpful way. \"\n",
    "        f\"User: {text}\\n\"\n",
    "        \"Assistant:\"\n",
    "    )\n",
    "\n",
    "    inputs = dialogpt_tokenizer.encode(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=256,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = dialogpt_model.generate(\n",
    "        inputs,\n",
    "        max_length=200,\n",
    "        pad_token_id=dialogpt_tokenizer.eos_token_id,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    response = dialogpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response.replace(text, \"\").strip()\n",
    "\n",
    "    if not response or len(response.split()) < 3:\n",
    "        response = \"I'm here to help. Can you tell me more about how you're feeling?\"\n",
    "\n",
    "    return response"
   ],
   "metadata": {
    "id": "duYsQVZcobH8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Part 5: Chatbot Interface**"
   ],
   "metadata": {
    "id": "AFW_7eoghWa4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "import gradio as gr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ],
   "metadata": {
    "id": "bTu2DlqbhW9O",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7a9cc20b-2f85-407a-b341-4ad65e3d03c8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load models and tokenizers\n",
    "try:\n",
    "    sentiment_tokenizer = AutoTokenizer.from_pretrained(\"/content/sentiment_model_improved\")\n",
    "    sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"/content/sentiment_model_improved\").to(device)\n",
    "    crisis_tokenizer = AutoTokenizer.from_pretrained(\"/content/crisis_model\")\n",
    "    crisis_model = AutoModelForSequenceClassification.from_pretrained(\"/content/crisis_model\").to(device)\n",
    "    dialogpt_tokenizer = AutoTokenizer.from_pretrained(\"/content/dialogpt_finetuned\")\n",
    "    dialogpt_model = AutoModelForCausalLM.from_pretrained(\"/content/dialogpt_finetuned\").to(device)\n",
    "    dialogpt_tokenizer.pad_token = dialogpt_tokenizer.eos_token\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Model files not found. Ensure /content/sentiment_model_improved, /content/crisis_model, and /content/dialogpt_finetuned exist. {e}\")\n",
    "    exit()"
   ],
   "metadata": {
    "id": "VpMeuHbBhi5B"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 1: Define prediction functions\n",
    "def predict_sentiment(text):\n",
    "    try:\n",
    "        inputs = sentiment_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = sentiment_model(**inputs)\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "        return {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2: \"POSITIVE\"}[pred]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentiment prediction: {e}\")\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "def predict_crisis(text):\n",
    "    try:\n",
    "        inputs = crisis_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = crisis_model(**inputs)\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "        return pred == 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error in crisis prediction: {e}\")\n",
    "        return False\n",
    "\n",
    "def generate_response(text):\n",
    "    try:\n",
    "        # Format input with a clear delimiter\n",
    "        prompt = f\"User: {text} Assistant: \" + dialogpt_tokenizer.eos_token\n",
    "        inputs = dialogpt_tokenizer.encode(prompt, return_tensors=\"pt\", max_length=128, truncation=True).to(device)\n",
    "        outputs = dialogpt_model.generate(\n",
    "            inputs,\n",
    "            max_length=150,\n",
    "            pad_token_id=dialogpt_tokenizer.eos_token_id,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        response = dialogpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Extract only the assistant's response\n",
    "        response = response.split(\"Assistant: \")[-1].strip() if \"Assistant: \" in response else response.replace(f\"User: {text}\", \"\").strip()\n",
    "        return response if response else \"I'm here to help. Could you share a bit more?\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in response generation: {e}\")\n",
    "        return \"I'm here to help. Could you share a bit more?\""
   ],
   "metadata": {
    "id": "wfQpxOdthlzg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Combine logic for chatbot\n",
    "def chatbot_logic(user_input):\n",
    "    # Check for crisis\n",
    "    if predict_crisis(user_input):\n",
    "        return (\"I'm really concerned about how you're feeling. Please reach out to a trusted person or contact a helpline like the National Suicide Prevention Lifeline at 1-800-273-8255. I'm here to listen, too.\")\n",
    "\n",
    "    # Get sentiment and generate response\n",
    "    sentiment = predict_sentiment(user_input)\n",
    "    response = generate_response(user_input)\n",
    "\n",
    "    # Tailor response based on sentiment\n",
    "    if sentiment == \"NEGATIVE\":\n",
    "        response += \" I\u2019m here for you. Would you like some coping strategies, like deep breathing or journaling?\"\n",
    "    elif sentiment == \"POSITIVE\":\n",
    "        response += \" That\u2019s wonderful to hear! Want to tell me more?\"\n",
    "    else:\n",
    "        response += \" Thanks for sharing. How can I help you further, perhaps with some tips or resources?\"\n",
    "\n",
    "    return response"
   ],
   "metadata": {
    "id": "-DQUvRlrhoC_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Combine logic for chatbot\n",
    "def chatbot_logic(user_input):\n",
    "    if not user_input or not isinstance(user_input, str):\n",
    "        return \"Please enter a valid message.\"\n",
    "\n",
    "    # Check for crisis\n",
    "    if predict_crisis(user_input):\n",
    "        return (\"I'm really concerned about how you're feeling. Please reach out to a trusted person or contact a helpline like the National Suicide Prevention Lifeline at 1-800-273-8255. I'm here to listen, too.\")\n",
    "\n",
    "    # Get sentiment and generate response\n",
    "    sentiment = predict_sentiment(user_input)\n",
    "    response = generate_response(user_input)\n",
    "\n",
    "    # Tailor response based on sentiment\n",
    "    if sentiment == \"NEGATIVE\":\n",
    "        response += \" I\u2019m here for you. Would you like some coping strategies, like deep breathing or journaling?\"\n",
    "    elif sentiment == \"POSITIVE\":\n",
    "        response += \" That\u2019s wonderful to hear! Want to tell me more?\"\n",
    "    else:\n",
    "        response += \" Thanks for sharing. How can I help you further, perhaps with some tips or resources?\"\n",
    "\n",
    "    return response"
   ],
   "metadata": {
    "id": "pBmDCYQxhqgC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3: CLI Interface\n",
    "def run_chatbot():\n",
    "    print(\"Mental Health Support Chatbot\")\n",
    "    print(\"Share your thoughts or feelings, and I'll try to help. Type 'exit' to quit.\")\n",
    "    print(\"If you're in crisis, I'll suggest resources.\")\n",
    "    print(\"Made by Hardik\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Your Message: \").strip()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye. Take care!\")\n",
    "            break\n",
    "        if not user_input:\n",
    "            print(\"Please enter a message.\")\n",
    "            continue\n",
    "        response = chatbot_logic(user_input)\n",
    "        print(f\"Response: {response}\\n\")"
   ],
   "metadata": {
    "id": "QKSoGtey4_G5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4: Test chatbot programmatically\n",
    "def test_chatbot():\n",
    "    print(\"\\nTesting chatbot with sample inputs:\")\n",
    "    test_texts = [\n",
    "        \"I\u2019m really struggling with anxiety\",\n",
    "        \"I just got promoted and I\u2019m thrilled\",\n",
    "        \"What are some ways to cope with sadness?\",\n",
    "        \"Life feels meaningless sometimes\"\n",
    "    ]\n",
    "    for text in test_texts:\n",
    "        response = chatbot_logic(text)\n",
    "        print(f\"Input: {text}\\nResponse: {response}\\n\")"
   ],
   "metadata": {
    "id": "d3H81EEhhwhb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5: Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    test_chatbot()  # Run tests first\n",
    "    run_chatbot()   # Then start CLI"
   ],
   "metadata": {
    "id": "N8R4-qT4hzEt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cb60b46c-6217-4814-d395-3369b9ff4522"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Testing chatbot with sample inputs:\n",
      "Input: I\u2019m really struggling with anxiety\n",
      "Response: Hello, and thank you for your question. I am so sorry that you are having such a difficult time dealing with your anxiety. \u00a0I hope you can find the support you need. I\u2019m here for you. Would you like some coping strategies, like deep breathing or journaling?\n",
      "\n",
      "Input: I just got promoted and I\u2019m thrilled\n",
      "Response: \u201c Congratulations on your promotion \u201d That\u2019s wonderful to hear! Want to tell me more?\n",
      "\n",
      "Input: What are some ways to cope with sadness?\n",
      "Response: I'm sorry to hear about your loss of your mother. I'm sure you can find some comfort in the fact that you lost her, but I'd like to remind you that there are a lot of things that can be done to help you cope. \u00a0You can also talk to a counselor about how you are coping with your sadness. Thanks for sharing. How can I help you further, perhaps with some tips or resources?\n",
      "\n",
      "Input: Life feels meaningless sometimes\n",
      "Response: I know that feeling all too well.   How can I help you feel more meaningful? I\u2019m here for you. Would you like some coping strategies, like deep breathing or journaling?\n",
      "\n",
      "Mental Health Support Chatbot\n",
      "Share your thoughts or feelings, and I'll try to help. Type 'exit' to quit.\n",
      "If you're in crisis, I'll suggest resources.\n",
      "Made by Hardik\n",
      "\n",
      "Your Message: I\u2019m really struggling with anxiety\n",
      "Response: Hello, and thank you for your question. I am so sorry that you are having such a difficult time dealing with your anxiety. \u00a0I hope you can find the support you need. I\u2019m here for you. Would you like some coping strategies, like deep breathing or journaling?\n",
      "\n",
      "Your Message: exit\n",
      "Goodbye. Take care!\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}